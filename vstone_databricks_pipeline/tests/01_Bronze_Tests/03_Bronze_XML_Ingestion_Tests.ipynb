{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6aa1d265-2faf-4c1c-8f7a-1eb33f420ece",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"/Workspace/Users/ruchika.b.mhetre@v4c.ai/vstone_project/vstone_databricks_pipeline/src/notebooks/00_Setup/project_config\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af7bd189-13ff-4367-a423-9c06ee21c568",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col, expr\n",
    "from datetime import date\n",
    "\n",
    "# 1. Create mock data mimicking raw XML read (where everything is often initially a string)\n",
    "mock_xml_raw = spark.createDataFrame([\n",
    "    Row(id=\"XML_01\", marka=\"BMW\", model=\"X5\", year=\"2022\", cost=\"60000.50\", \n",
    "        has_license=\"true\", date=\"2023-01-15T10:00:00Z\", power=\"300\", \n",
    "        probeg=\"5000\", R=\"255\", G=\"0\", B=\"0\"),\n",
    "    Row(id=\"XML_02\", marka=\"Audi\", model=\"A6\", year=\"bad_year\", cost=\"55000\", \n",
    "        has_license=\"0\", date=\"12.12.2022\", power=\"250\", \n",
    "        probeg=\"12000\", R=\"0\", G=\"255\", B=\"0\")\n",
    "])\n",
    "\n",
    "# 2. Apply your transformation logic (The code you provided)\n",
    "# Note: I'm using the logic from your snippet\n",
    "df_xml_test = mock_xml_raw.select(\n",
    "    col(\"id\").cast(\"string\"),\n",
    "    expr(\"try_cast(year as int)\").alias(\"year\"),\n",
    "    expr(\"try_cast(cost as double)\").alias(\"cost\"),\n",
    "    expr(\"try_cast(has_license as boolean)\").alias(\"has_license\"),\n",
    "    expr(\"\"\"\n",
    "        coalesce(\n",
    "            try_to_date(date, \"yyyy-MM-dd'T'HH:mm:ss'Z'\"),\n",
    "            try_to_date(date, 'dd.MM.yyyy'),\n",
    "            try_to_date(date, 'yyyy-MM-dd')\n",
    "        )\n",
    "    \"\"\").alias(\"date\"),\n",
    "    expr(\"try_cast(power as int)\").alias(\"power\"),\n",
    "    expr(\"try_cast(R as int)\").alias(\"R\")\n",
    ")\n",
    "\n",
    "# 3. Assertions\n",
    "results = df_xml_test.collect()\n",
    "\n",
    "# Test Case: ISO Timestamp to Date\n",
    "assert results[0][\"date\"] == date(2023, 1, 15), \"Failed: ISO XML date conversion\"\n",
    "\n",
    "# Test Case: Dotted Format to Date\n",
    "assert results[1][\"date\"] == date(2022, 12, 12), \"Failed: Dotted XML date conversion\"\n",
    "\n",
    "# Test Case: Error Handling for Years\n",
    "assert results[1][\"year\"] is None, \"Failed: Non-numeric year should be Null\"\n",
    "\n",
    "# Test Case: Boolean Mapping\n",
    "assert results[0][\"has_license\"] is True, \"Failed: 'true' string to Boolean\"\n",
    "\n",
    "# Test Case: RGB Integers\n",
    "assert results[0][\"R\"] == 255, \"Failed: RGB color casting\"\n",
    "\n",
    "print(\"✅ XML Logic Transformation Test: PASSED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b18bb966-9ca9-4601-a82c-7639254e6550",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target_table = f\"{catalog_name}.{schema_name}.bronze_transactions\"\n",
    "\n",
    "# 1. Assert the source exists in the table\n",
    "xml_records = spark.table(target_table).filter(col(\"source_file\") == \"chunk4_xml\")\n",
    "record_count = xml_records.count()\n",
    "assert record_count > 0, f\"Failure: No records found for 'chunk4_xml' in {target_table}\"\n",
    "\n",
    "# 2. Assert Schema Evolution (New columns should exist)\n",
    "actual_columns = spark.table(target_table).columns\n",
    "expected_new_cols = [\"power\", \"probeg\", \"R\", \"G\", \"B\"]\n",
    "\n",
    "for c in expected_new_cols:\n",
    "    assert c in actual_columns, f\"Schema Error: Column {c} was not added to the Delta table!\"\n",
    "\n",
    "# 3. Data Quality Check: power should be numeric\n",
    "# We check if 'power' contains only integers (or nulls), not string representations\n",
    "power_dtype = [dtype for name, dtype in spark.table(target_table).dtypes if name == 'power'][0]\n",
    "assert power_dtype == 'int', f\"Type Error: 'power' column is {power_dtype}, expected int\"\n",
    "\n",
    "# 4. Filter Check: ID should never be null (due to your .filter(col(\"id\").isNotNull()) logic)\n",
    "null_id_count = xml_records.filter(col(\"id\").isNull()).count()\n",
    "assert null_id_count == 0, \"Logic Error: Found NULL IDs in XML ingestion despite filter.\"\n",
    "\n",
    "print(f\"✅ XML Ingestion Verification: PASSED ({record_count} records verified)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c4efd47-49ff-460e-a824-c3b2a0546a19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_Bronze_XML_Ingestion_Tests",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
